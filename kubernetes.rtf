{\rtf1\ansi\ansicpg1252\cocoartf1671\cocoasubrtf600
{\fonttbl\f0\fswiss\fcharset0 Helvetica;\f1\fswiss\fcharset0 Helvetica-Bold;\f2\froman\fcharset0 Times-Roman;
}
{\colortbl;\red255\green255\blue255;\red0\green0\blue233;}
{\*\expandedcolortbl;;\cssrgb\c0\c0\c93333;}
\paperw11900\paperh16840\margl1440\margr1440\vieww25100\viewh12920\viewkind0
\deftab720
\pard\tx566\tx1133\tx1700\tx2267\tx2834\tx3401\tx3968\tx4535\tx5102\tx5669\tx6236\tx6803\pardeftab720\pardirnatural\partightenfactor0

\f0\fs24 \cf0 # Kubernetes orchestrates docker containers on those minion servers. The docker+application combo that gets deployed on the minion servers are called pods.\
\
# kubectl is the command line tool to do things in Kubernetes\
\
# Out of the 4 servers mark one as the master server\
\
# Now on master server do the following as root user:\
\
yum -y install wget nano tree\
\
systemctl stop firewalld\
systemctl disable firewalld\
\
yum -y install ntp\
systemctl start ntpd\
systemctl enable ntpd\
\
setenforce 0 \'97 to disable selinux\
\
yum -y install epel-release\
yum -y install kubernetes etcd\
\
NOTE: etcd is a registry service package used, if you have multiple applications and need to connect using service. etcd is used. Its the independent tool build by the codes team for service registry purpose.\
\
etcd can also be used irrespective of the kubernetes.\
\
\
\'97 Kubernetes Server Config:\
\
# vi /etc/etcd/etcd.conf\
Make ETCD_LISTEN_CLIENT_URLS="http://0.0.0.0:2379" -> as 0.0.0.0\
\
# vi /etc/kubernetes/apiserver\
KUBE_API_ADDRESS="--address=0.0.0.0" -> do this\
KUBE_ADMISSION_CONTROL="--admission-control=NamespaceLifecycle,NamespaceExists,LimitRanger,ResourceQuota" -> keep only these parameters, remove other parameters in this line\
Uncomment KUBE_API_PORT & KUBELET_PORT\
\
\
\'97 Start Kubernetes Server services:\
# systemctl start etcd\
# systemctl enable etcd\
\
# systemctl start kube-apiserver\
# systemctl enable kube-apiserver\
\
# systemctl start kube-controller-manager\
# systemctl enable kube-controller-manager\
\
# systemctl start kube-scheduler\
# systemctl enable kube-scheduler\
\
\
\'97 Kubernetes networking configuration:\
atomic.io is the file to setup docker subneting in Kubernetes. And its called flannel networking setup.\
Flannel is the networking concept of Kubernetes cluster. Docker Networking Component.\
\
[root@master ~]# etcdctl mk /atomic.io/network/config '\{"Network":"172.17.0.0/16"\}'\
\{"Network":"172.17.0.0/16"\}\
\
\
\'97 Now Run:\
[root@master ~]# kubectl get nodes\
No resources found.\
\
\
It means Nodes i.e. minions are not setup. So we need to setup the minions.\
\
\pard\tx566\tx1133\tx1700\tx2267\tx2834\tx3401\tx3968\tx4535\tx5102\tx5669\tx6236\tx6803\pardeftab720\pardirnatural\partightenfactor0

\f1\b \cf0 Minion1\
======
\f0\b0 \
Vagrant ssh minion1\
\
systemctl stop firewalld\
systemctl disable firewalld\
setenforce 0\
\
yum install -y wget nano tree\
yum -y install kubernetes flannel\
\
vi /etc/sysconfig/flanneld \'97> Add the IP which we have assigned in Vagrantfile, FLANNEL_ETCD_ENDPOINTS="http://192.168.33.10:2379" (Added master IP which is 192.168.33.10)\
\
vi /etc/kubernetes/config \'97>  Add master IP 192.168.33.10 to below line. We have to add master IP here, so that we say to minion1 that, master API Kube server is 192.168.33.10\
KUBE_MASTER="--master=http://192.168.33.10:8080"\
\
\
vi /etc/kubernetes/kubelet \'97>\
KUBELET_ADDRESS="--address=0.0.0.0" -> Make this 0.0.0.0\
KUBELET_PORT="--port=10250" \'97> Uncomment this line\
KUBELET_HOSTNAME="--hostname-override=192.168.33.20" \'97> Here give the IP minion1 IP i.e. 192.168.33.20\
KUBELET_API_SERVER="--api-servers=http://192.168.33.10:8080" \'97> Here give the master API server IP 192.168.33.10\
\
\
Now, start the services in minion1\
\
# systemctl start kube-proxy\
# systemctl enable kube-proxy\
\
# systemctl start kubelet\
# systemctl enable kubelet\
\
#systemctl restart docker\
# systemctl enable docker\
\
# systemctl start flanneld\
# systemctl enable flanneld\
\

\f1\b Note:
\f0\b0  kubelet is client component and flannel is networking component. Kubelet will created docker environment in each of the minion servers and maintains docker containers.\
Suppose 2 docker containers needs to be connected from minion1 & minion2, then flannel network will come into the picture which will connect the docker containers within minions. It has nothing to do with the actual VM network. That is as usual networking for VMs.\
The IP which we have assigned 172.17.0.0/16 is flannel network. And VM IPs are as usual comes from the Vagrantfile which we have assigned.\
\
Do the Same Setup and Configuration in minion2 & minion3\
\
\
Master\
=====\
[root@master ~]# kubectl run my-nginx --image=nginx   (like docker run, we have kubectl run and its called deployment in terms of kubernetes, like created image for deployment)\
deployment "my-nginx" created\
[root@master ~]#\
\
[root@master ~]# kubectl get deployment\
NAME       DESIRED   CURRENT   UP-TO-DATE   AVAILABLE   AGE\
my-nginx   1         1         1            0           35s\
[root@master ~]#\
\
[root@master ~]# kubectl get pod\
NAME                        READY     STATUS              RESTARTS   AGE\
my-nginx-2723453542-8sgkd   0/1       ContainerCreating   0          1m\
[root@master ~]#\
\
POD: Pod is either a single container or a group of container which is launched at the same time.\
\pard\pardeftab720\sl280\partightenfactor0
\cf0 \
\pard\tx566\tx1133\tx1700\tx2267\tx2834\tx3401\tx3968\tx4535\tx5102\tx5669\tx6236\tx6803\pardeftab720\pardirnatural\partightenfactor0
\cf0 \
# kubectl describe pod my-nginx-2723453542-8sgkd  \
Name:		my-nginx-2723453542-8sgkd\
Namespace:	default\
Node:		192.168.33.40/192.168.33.40\
Start Time:	Wed, 24 Jul 2019 09:22:42 +0000\
Labels:		pod-template-hash=2723453542\
		run=my-nginx\
Status:		Pending\
IP:\
Controllers:	ReplicaSet/my-nginx-2723453542\
ePull: "image pull failed for registry.access.redhat.com/rhel7/pod-infrastructure:latest, this may be because there are no credentials on this request.  details: (open /etc/docker/certs.d/registry.access.redhat.com/redhat-ca.crt: no such file or directory)"\
\
\
We may get above issue sometimes, i.e. image pull failed. Is it below Link:\
\pard\pardeftab720\sl280\partightenfactor0
{\field{\*\fldinst{HYPERLINK "https://unix.stackexchange.com/questions/400938/unable-to-pull-images-in-kubernetes"}}{\fldrslt 
\f2 \cf2 \expnd0\expndtw0\kerning0
\ul https://unix.stackexchange.com/questions/400938/unable-to-pull-images-in-kubernetes}}
\f2 \cf2 \expnd0\expndtw0\kerning0
\ul \
Comment the below line to fix it:\
KUBELET_POD_INFRA_CONTAINER="--pod-infra-containerimage=registry.access.redhat.com/rhel7/pod-infrastructure:latest" in /etc/kubernetes/kubelet on each of slave & master\
And also restart all services in master & minions\
\pard\tx566\tx1133\tx1700\tx2267\tx2834\tx3401\tx3968\tx4535\tx5102\tx5669\tx6236\tx6803\pardeftab720\pardirnatural\partightenfactor0

\f0 \cf0 \kerning1\expnd0\expndtw0 \ulnone \
After fixing it. Delete the deployment image Nginx and create my-nginx deployment image once again\'85..And then it will get created with its IP i.e. 172.17.92.2 in this case\
\
[root@master ~]# kubectl describe pod my-nginx-2723453542-5ldrr\
Name:		my-nginx-2723453542-5ldrr\
Namespace:	default\
Node:		192.168.33.30/192.168.33.30\
Start Time:	Thu, 25 Jul 2019 04:55:51 +0000\
Labels:		pod-template-hash=2723453542\
		run=my-nginx\
Status:		Running\
IP:		172.17.92.2\
Controllers:	ReplicaSet/my-nginx-2723453542\
\
\
\
# The Nginx image has been created in minion2 (192.168.33.30), so login to minion2 and install lynx to test the Nginx image\
yum install -y lynx\
ping 172.17.92.2 (To Test the connectivity, ping Nginx ip from minion2)\
\
\
# lynx <that docker IP>  [To Test the docker container, will show Nginx page]\
\
\
# To delete the POD:\
kubectl delete deployment my-nginx\
\
# To Verify:\
# kubectl get deployment\
# kubectl get pods\
\
\
\
\'97 Now Launch the POD Nginx and Expose the port\
========================================\
So, first remove the pod which we have created with the IP 172.17.92.2 and then relaunch it by exposing the port 80\
\
kubectl delete deployment my-nginx\
kubectl get deployment\
kubectl get pods\
\
# kubectl run my-nginx --image=nginx --port=80 \'97> Launching by exposing the port 80\
# kubectl get deployment\
# kubectl get pods\
# kubectl describe pod my-nginx-379829228-3jl5q\
\
This image got created in minion1 , install lynx there and test, lynx <ip of image>\
\
\
To create 2 images\
===============\
# kubectl run my-nginx --image=nginx --replicas=2 --port=80\
# kubectl get deployment\
# kubectl get pods\
\
\
# kubectl describe pod my-nginx-379829228-fq8jm - Running on minion3, 192.168.33.40\
# kubectl describe pod my-nginx-379829228-t62q9 - Running on minion2, 192.168.33.30\
\
2 images will be created and they both will run on 2 different minions.\
\
\
[root@master ~]# kubectl get pods\
NAME                       READY     STATUS    RESTARTS   AGE\
my-nginx-379829228-fq8jm   1/1       Running   0          20m\
my-nginx-379829228-g2gjd   1/1       Running   0          4m \'97\'97> Running on minion1, 192.168.33.20\
my-nginx-379829228-t62q9   1/1       Unknown   0          20m\
\
\
# kubectl run my-nginx --image=nginx --replicas=2 --port=80\
\
Explanation\
==========\
The Above command means, like we are giving the instruction to kubernetes to maintain the 2 replicas i.e. 2 sets of the nginx image.\
Hence, if minion2 is down. It will automatically create a another docker image in different minion after 5 min. Because are instructing\
Kubernetes to maintain 2 replicas always in above command. We can see above, its showing 3 images, and the image which was running\
On minion2 is showing as \'93Unknown\'94. Since, minion2 we have bring down. So, it has started the image \'93my-nginx-379829228-g2gjd\'94 in minion1\
\
\
Q. Can we create the images explicitly on the minion where we want?\
Ans: No, we cannot create. Its more of the cloud technology not like Vmware (can select which Esx host, vm will be created).\
        Its Kubernetes, which will decide which minion is better for this app to be created and it will be decided by kubernetes.\
\
\
\
\
\
\
\
\
\
\
\
\
\
\
\
\
\
\
\
\
 \
\
\
\
\
\
\
\
\
\
\
\
\
\
\
\
\
\
\
\
\
\
\
\
}